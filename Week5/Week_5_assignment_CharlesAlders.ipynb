{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165166dd",
   "metadata": {},
   "source": [
    "# DS Automation Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195af74",
   "metadata": {},
   "source": [
    "Using our prepared churn data from week 2:\n",
    "- use pycaret to find an ML algorithm that performs best on the data\n",
    "    - Choose a metric you think is best to use for finding the best model; by default, it is accuracy but it could be AUC, precision, recall, etc. The week 3 FTE has some information on these different metrics.\n",
    "- save the model to disk\n",
    "- create a Python script/file/module with a function that takes a pandas dataframe as an input and returns the probability of churn for each row in the dataframe\n",
    "    - your Python file/function should print out the predictions for new data (new_churn_data.csv)\n",
    "    - the true values for the new data are [1, 0, 0, 1, 0] if you're interested\n",
    "- test your Python module and function with the new data, new_churn_data.csv\n",
    "- write a short summary of the process and results at the end of this notebook\n",
    "- upload this Jupyter Notebook and Python file to a Github repository, and turn in a link to the repository in the week 5 assignment dropbox\n",
    "\n",
    "*Optional* challenges:\n",
    "- return the probability of churn for each new prediction, and the percentile where that prediction is in the distribution of probability predictions from the training dataset (e.g. a high probability of churn like 0.78 might be at the 90th percentile)\n",
    "- use other autoML packages, such as TPOT, H2O, MLBox, etc, and compare performance and features with pycaret\n",
    "- create a class in your Python module to hold the functions that you created\n",
    "- accept user input to specify a file using a tool such as Python's `input()` function, the `click` package for command-line arguments, or a GUI\n",
    "- Use the unmodified churn data (new_unmodified_churn_data.csv) in your Python script. This will require adding the same preprocessing steps from week 2 since this data is like the original unmodified dataset from week 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60c76174",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Assignment 5 - Charles Alders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56fb9736",
   "metadata": {},
   "source": [
    "## Imports and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "476ed965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c517e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>total_charges_tenure_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7590-VHVEG</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>29.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5575-GNVDE</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>55.573529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668-QPYBK</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>54.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795-CFOCW</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>40.905556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9237-HQITU</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>75.825000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tenure  PhoneService  Contract  PaymentMethod  MonthlyCharges  \\\n",
       "customerID                                                                  \n",
       "7590-VHVEG       1             0         0              0           29.85   \n",
       "5575-GNVDE      34             1         1              1           56.95   \n",
       "3668-QPYBK       2             1         0              1           53.85   \n",
       "7795-CFOCW      45             0         1              2           42.30   \n",
       "9237-HQITU       2             1         0              0           70.70   \n",
       "\n",
       "            TotalCharges  Churn  total_charges_tenure_ratio  \n",
       "customerID                                                   \n",
       "7590-VHVEG         29.85      0                   29.850000  \n",
       "5575-GNVDE       1889.50      0                   55.573529  \n",
       "3668-QPYBK        108.15      1                   54.075000  \n",
       "7795-CFOCW       1840.75      0                   40.905556  \n",
       "9237-HQITU        151.65      1                   75.825000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"prepped_churn_data.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "213188d4",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "295be5b8",
   "metadata": {},
   "source": [
    "Splitting data into features and targets, then into train and test sets for our model. Using stratify to keep the same proportion of target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b64cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(\"Churn\", axis=1)\n",
    "targets = df.Churn\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, targets, stratify=targets, random_state=26)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e72608f9",
   "metadata": {},
   "source": [
    "## Using TPOT to find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a5d1d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28e2a0655514204a496fcb69b4d094d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.7961695009757457\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.7965470291464698\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.7965470291464698\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.7965470291464698\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.7969290538413807\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(CombineDFs(input_matrix, input_matrix), bootstrap=True, criterion=entropy, max_features=0.25, min_samples_leaf=3, min_samples_split=7, n_estimators=100)\n",
      "Wall time: 2min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(generations=5, n_jobs=-1, population_size=50, random_state=26,\n",
       "               scoring='accuracy', verbosity=2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, cv=5, random_state=26, scoring='accuracy', verbosity=2, n_jobs=-1)\n",
    "tpot.fit(x_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75df15a1",
   "metadata": {},
   "source": [
    "Looks like ExtraTreesClassifier is best algorithm for this dataset. Below compares TPOT's predictions to the actual values in the test set. Looks pretty good, but I do see one incorrect prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b73272d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1] ... [1 0 0 0 0]\n",
      "customerID\n",
      "2969-WGHQO    0\n",
      "8034-RYTVV    0\n",
      "7025-WCBNE    0\n",
      "6137-MFAJN    0\n",
      "1792-UXAFY    1\n",
      "             ..\n",
      "6967-QIQRV    0\n",
      "9761-XUJWD    0\n",
      "3705-RHRFR    0\n",
      "4801-KFYKL    0\n",
      "9357-UJRUN    0\n",
      "Name: Churn, Length: 1758, dtype: int64\n",
      "\n",
      "\n",
      "Accuracy of TPOT predictions: 0.7957906712172924\n"
     ]
    }
   ],
   "source": [
    "# For some reason this gave me a warning when I ran it on my MacBook, but not when I run it on Windows 10... oh well?\n",
    "# I fixed it on MacOS by fitting the model with x_train.values, but it cause the best model to be far more complex.\n",
    "\n",
    "predictions = tpot.predict(x_test)\n",
    "\n",
    "# Comparing predictions to the test set.\n",
    "print(predictions[0:5], \"...\", predictions[-6:-1]) # By default, printing predictions was only showing the first 3.\n",
    "print(y_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f'\\n\\nAccuracy of TPOT predictions: {accuracy_score(y_test, predictions)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a257869",
   "metadata": {},
   "source": [
    "According to the output above, the ExtraTreesClassifier had the highest accuracy - 79.57%, which is the accuracy of TPOT's predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f810e770",
   "metadata": {},
   "source": [
    "## Exporting and running pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ab83f66",
   "metadata": {},
   "source": [
    "Exporting the best algorithm to a Python file for easy access and reproducing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cc903b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('tpot_churn_pipeline.py')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d5f9782",
   "metadata": {},
   "source": [
    "I modified the file to include my own file path, and changed the target column to \"Churn\" from \"target\".\n",
    "For reference, the code from the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e917d269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.ensemble</span> <span class=\"kn\">import</span> <span class=\"n\">ExtraTreesClassifier</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.pipeline</span> <span class=\"kn\">import</span> <span class=\"n\">make_pipeline</span><span class=\"p\">,</span> <span class=\"n\">make_union</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">tpot.builtins</span> <span class=\"kn\">import</span> <span class=\"n\">StackingEstimator</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">tpot.export_utils</span> <span class=\"kn\">import</span> <span class=\"n\">set_param_recursive</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.preprocessing</span> <span class=\"kn\">import</span> <span class=\"n\">FunctionTransformer</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">copy</span> <span class=\"kn\">import</span> <span class=\"n\">copy</span>\n",
       "\n",
       "<span class=\"c1\"># NOTE: Make sure that the outcome column is labeled &#39;target&#39; in the data file</span>\n",
       "<span class=\"n\">tpot_data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">&#39;C:\\Users\\Charlie\\Desktop\\Charlie\\GitHub\\MSDS600\\Week5\\Assignment\\prepped_churn_data.csv&#39;</span><span class=\"p\">,</span> <span class=\"n\">index_col</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"n\">tpot_data</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;Churn&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">testing_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">,</span> <span class=\"n\">testing_target</span> <span class=\"o\">=</span> \\\n",
       "            <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">tpot_data</span><span class=\"p\">[</span><span class=\"s1\">&#39;Churn&#39;</span><span class=\"p\">],</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">26</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Average CV score on the training set was: 0.7969290538413807</span>\n",
       "<span class=\"n\">exported_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">make_pipeline</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">make_union</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">FunctionTransformer</span><span class=\"p\">(</span><span class=\"n\">copy</span><span class=\"p\">),</span>\n",
       "        <span class=\"n\">FunctionTransformer</span><span class=\"p\">(</span><span class=\"n\">copy</span><span class=\"p\">)</span>\n",
       "    <span class=\"p\">),</span>\n",
       "    <span class=\"n\">ExtraTreesClassifier</span><span class=\"p\">(</span><span class=\"n\">bootstrap</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">criterion</span><span class=\"o\">=</span><span class=\"s2\">&quot;entropy&quot;</span><span class=\"p\">,</span> <span class=\"n\">max_features</span><span class=\"o\">=</span><span class=\"mf\">0.25</span><span class=\"p\">,</span> <span class=\"n\">min_samples_leaf</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">min_samples_split</span><span class=\"o\">=</span><span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"n\">n_estimators</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">)</span>\n",
       "<span class=\"p\">)</span>\n",
       "<span class=\"c1\"># Fix random state for all the steps in exported pipeline</span>\n",
       "<span class=\"n\">set_param_recursive</span><span class=\"p\">(</span><span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">steps</span><span class=\"p\">,</span> <span class=\"s1\">&#39;random_state&#39;</span><span class=\"p\">,</span> <span class=\"mi\">26</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">testing_features</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">results</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{ensemble} \\PY{k+kn}{import} \\PY{n}{ExtraTreesClassifier}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{pipeline} \\PY{k+kn}{import} \\PY{n}{make\\PYZus{}pipeline}\\PY{p}{,} \\PY{n}{make\\PYZus{}union}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{tpot}\\PY{n+nn}{.}\\PY{n+nn}{builtins} \\PY{k+kn}{import} \\PY{n}{StackingEstimator}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{tpot}\\PY{n+nn}{.}\\PY{n+nn}{export\\PYZus{}utils} \\PY{k+kn}{import} \\PY{n}{set\\PYZus{}param\\PYZus{}recursive}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{preprocessing} \\PY{k+kn}{import} \\PY{n}{FunctionTransformer}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{copy} \\PY{k+kn}{import} \\PY{n}{copy}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} NOTE: Make sure that the outcome column is labeled \\PYZsq{}target\\PYZsq{} in the data file}\n",
       "\\PY{n}{tpot\\PYZus{}data} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{read\\PYZus{}csv}\\PY{p}{(}\\PY{l+s+sa}{r}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{C:}\\PY{l+s+s1}{\\PYZbs{}}\\PY{l+s+s1}{Users}\\PY{l+s+s1}{\\PYZbs{}}\\PY{l+s+s1}{Charlie}\\PY{l+s+s1}{\\PYZbs{}}\\PY{l+s+s1}{Desktop}\\PY{l+s+s1}{\\PYZbs{}}\\PY{l+s+s1}{Charlie}\\PY{l+s+s1}{\\PYZbs{}}\\PY{l+s+s1}{GitHub}\\PY{l+s+s1}{\\PYZbs{}}\\PY{l+s+s1}{MSDS600}\\PY{l+s+s1}{\\PYZbs{}}\\PY{l+s+s1}{Week5}\\PY{l+s+s1}{\\PYZbs{}}\\PY{l+s+s1}{Assignment}\\PY{l+s+s1}{\\PYZbs{}}\\PY{l+s+s1}{prepped\\PYZus{}churn\\PYZus{}data.csv}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{index\\PYZus{}col}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{)}\n",
       "\\PY{n}{features} \\PY{o}{=} \\PY{n}{tpot\\PYZus{}data}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Churn}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{testing\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{,} \\PY{n}{testing\\PYZus{}target} \\PY{o}{=} \\PYZbs{}\n",
       "            \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{features}\\PY{p}{,} \\PY{n}{tpot\\PYZus{}data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Churn}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{26}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Average CV score on the training set was: 0.7969290538413807}\n",
       "\\PY{n}{exported\\PYZus{}pipeline} \\PY{o}{=} \\PY{n}{make\\PYZus{}pipeline}\\PY{p}{(}\n",
       "    \\PY{n}{make\\PYZus{}union}\\PY{p}{(}\n",
       "        \\PY{n}{FunctionTransformer}\\PY{p}{(}\\PY{n}{copy}\\PY{p}{)}\\PY{p}{,}\n",
       "        \\PY{n}{FunctionTransformer}\\PY{p}{(}\\PY{n}{copy}\\PY{p}{)}\n",
       "    \\PY{p}{)}\\PY{p}{,}\n",
       "    \\PY{n}{ExtraTreesClassifier}\\PY{p}{(}\\PY{n}{bootstrap}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{,} \\PY{n}{criterion}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{entropy}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{max\\PYZus{}features}\\PY{o}{=}\\PY{l+m+mf}{0.25}\\PY{p}{,} \\PY{n}{min\\PYZus{}samples\\PYZus{}leaf}\\PY{o}{=}\\PY{l+m+mi}{3}\\PY{p}{,} \\PY{n}{min\\PYZus{}samples\\PYZus{}split}\\PY{o}{=}\\PY{l+m+mi}{7}\\PY{p}{,} \\PY{n}{n\\PYZus{}estimators}\\PY{o}{=}\\PY{l+m+mi}{100}\\PY{p}{)}\n",
       "\\PY{p}{)}\n",
       "\\PY{c+c1}{\\PYZsh{} Fix random state for all the steps in exported pipeline}\n",
       "\\PY{n}{set\\PYZus{}param\\PYZus{}recursive}\\PY{p}{(}\\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{steps}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{random\\PYZus{}state}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+m+mi}{26}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{)}\n",
       "\\PY{n}{results} \\PY{o}{=} \\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{predict}\\PY{p}{(}\\PY{n}{testing\\PYZus{}features}\\PY{p}{)}\n",
       "\n",
       "\\PY{n+nb}{print}\\PY{p}{(}\\PY{n}{results}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import numpy as np\n",
       "import pandas as pd\n",
       "from sklearn.ensemble import ExtraTreesClassifier\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.pipeline import make_pipeline, make_union\n",
       "from tpot.builtins import StackingEstimator\n",
       "from tpot.export_utils import set_param_recursive\n",
       "from sklearn.preprocessing import FunctionTransformer\n",
       "from copy import copy\n",
       "\n",
       "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
       "tpot_data = pd.read_csv(r'C:\\Users\\Charlie\\Desktop\\Charlie\\GitHub\\MSDS600\\Week5\\Assignment\\prepped_churn_data.csv', index_col=0)\n",
       "features = tpot_data.drop('Churn', axis=1)\n",
       "training_features, testing_features, training_target, testing_target = \\\n",
       "            train_test_split(features, tpot_data['Churn'], random_state=26)\n",
       "\n",
       "# Average CV score on the training set was: 0.7969290538413807\n",
       "exported_pipeline = make_pipeline(\n",
       "    make_union(\n",
       "        FunctionTransformer(copy),\n",
       "        FunctionTransformer(copy)\n",
       "    ),\n",
       "    ExtraTreesClassifier(bootstrap=True, criterion=\"entropy\", max_features=0.25, min_samples_leaf=3, min_samples_split=7, n_estimators=100)\n",
       ")\n",
       "# Fix random state for all the steps in exported pipeline\n",
       "set_param_recursive(exported_pipeline.steps, 'random_state', 26)\n",
       "\n",
       "exported_pipeline.fit(training_features, training_target)\n",
       "results = exported_pipeline.predict(testing_features)\n",
       "\n",
       "print(results)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Code\n",
    "Code('tpot_churn_pipeline_new.py')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "434c0f5f",
   "metadata": {},
   "source": [
    "Running the file using the magic %run command from Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39909aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "%run tpot_churn_pipeline_new.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21409cef",
   "metadata": {},
   "source": [
    "## Testing predictions with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c25f9344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>charge_per_tenure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9305-CKSKC</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>97.40</td>\n",
       "      <td>811.70</td>\n",
       "      <td>36.895455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452-KNGVK</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77.30</td>\n",
       "      <td>1701.95</td>\n",
       "      <td>212.743750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723-OKKJM</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.25</td>\n",
       "      <td>250.90</td>\n",
       "      <td>8.960714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7832-POPKP</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>101.70</td>\n",
       "      <td>3106.56</td>\n",
       "      <td>50.105806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6348-TACGU</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.15</td>\n",
       "      <td>3440.97</td>\n",
       "      <td>344.097000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tenure  PhoneService  Contract  PaymentMethod  MonthlyCharges  \\\n",
       "customerID                                                                  \n",
       "9305-CKSKC      22             1         0              2           97.40   \n",
       "1452-KNGVK       8             0         1              1           77.30   \n",
       "6723-OKKJM      28             1         0              0           28.25   \n",
       "7832-POPKP      62             1         0              2          101.70   \n",
       "6348-TACGU      10             0         0              1           51.15   \n",
       "\n",
       "            TotalCharges  charge_per_tenure  \n",
       "customerID                                   \n",
       "9305-CKSKC        811.70          36.895455  \n",
       "1452-KNGVK       1701.95         212.743750  \n",
       "6723-OKKJM        250.90           8.960714  \n",
       "7832-POPKP       3106.56          50.105806  \n",
       "6348-TACGU       3440.97         344.097000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.read_csv('new_churn_data.csv', index_col=0)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b42b45ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.predict(new_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42bf83f2",
   "metadata": {},
   "source": [
    "Trying predictions on the same data but using the exported Python file. Please let me know if this is not right! I see the same answers, so I am assuming this is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29c734a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot_churn_pipeline_new import exported_pipeline\n",
    "exported_pipeline.predict(new_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c49db562",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9533a1cd",
   "metadata": {},
   "source": [
    "This assignment utilized TPOT for automatic machine learning. After splitting the data into features/targets and train and test sets (how we have in previous weeks), I used the TPOT Classifier and fitted the data to the best model, which ended up being the ExtraTreesClassifier. The models were scored by accuracy, which ExtraTreesClassifier had the highest, at 79.57% accuracy. The model was then exported as a Python file. This is extremely useful as exporting the model allows others to use it for their churn data (with the same features) seamlessly. Lastly, I ran predictions on the new data using both the tpot.predict method in the notebook, and again utilizing the pipeline file. The predictions for the new data indicated that none of the five customers would churn. Keep in mind, the no-information rate is about 74%, while our best model has an accuracy of only 79.6%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "16f5b46f222e2a3e8d4adbf7141cae37b71ed37616e60735fa5d1164a1bc3ada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
